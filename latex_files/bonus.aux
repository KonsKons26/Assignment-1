\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}First bonus task: Using Optuna for hyperparameter tuning}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Migration to Optuna}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Hyperparameter tuning}{2}{subsection.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hyperparameter spaces for each model.}}{2}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:hyperparams}{{1}{2}{Hyperparameter spaces for each model}{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Results}{3}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Test metrics after tuning with \texttt  {Optuna}. ElasticNet in blue, SVR in orange, and Bayesian Ridge in green.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:optuna}{{1}{3}{Test metrics after tuning with \texttt {Optuna}. ElasticNet in blue, SVR in orange, and Bayesian Ridge in green}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Second bonus task: Converting the problem to a binary classification task}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview}{4}{subsection.2.1}\protected@file@percent }
\newlabel{eq:score}{{1}{4}{Overview}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Feature Selection}{4}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Selected features.}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:classif_features}{{2}{5}{Selected features}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Tuning}{5}{subsection.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hyperparameter spaces for each model.}}{5}{table.caption.5}\protected@file@percent }
\newlabel{tab:hyperparams_classif}{{2}{5}{Hyperparameter spaces for each model}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Results}{5}{subsection.2.4}\protected@file@percent }
\newlabel{fig:logreg_acc}{{3a}{6}{Accuracy}{figure.caption.6}{}}
\newlabel{sub@fig:logreg_acc}{{a}{6}{Accuracy}{figure.caption.6}{}}
\newlabel{fig:logreg_prec}{{3b}{6}{Precision}{figure.caption.6}{}}
\newlabel{sub@fig:logreg_prec}{{b}{6}{Precision}{figure.caption.6}{}}
\newlabel{fig:logreg_rec}{{3c}{6}{Recall}{figure.caption.6}{}}
\newlabel{sub@fig:logreg_rec}{{c}{6}{Recall}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Logistic Regression: Results based on the validation set. Accuracy, precision, and recall for the baseline, feature selection, and tuned models (baseline in blue, feature selection in orange, and tuned in green).}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:logreg}{{3}{6}{Logistic Regression: Results based on the validation set. Accuracy, precision, and recall for the baseline, feature selection, and tuned models (baseline in blue, feature selection in orange, and tuned in green)}{figure.caption.6}{}}
\newlabel{fig:gnb_acc}{{4a}{6}{Accuracy}{figure.caption.7}{}}
\newlabel{sub@fig:gnb_acc}{{a}{6}{Accuracy}{figure.caption.7}{}}
\newlabel{fig:gnb_prec}{{4b}{6}{Precision}{figure.caption.7}{}}
\newlabel{sub@fig:gnb_prec}{{b}{6}{Precision}{figure.caption.7}{}}
\newlabel{fig:gnb_rec}{{4c}{6}{Recall}{figure.caption.7}{}}
\newlabel{sub@fig:gnb_rec}{{c}{6}{Recall}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Gaussian Naive Bayes: Results based on the validation set. Accuracy, precision, and recall for the baseline, feature selection, and tuned models (baseline in blue, feature selection in orange, and tuned in green).}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:gnb}{{4}{6}{Gaussian Naive Bayes: Results based on the validation set. Accuracy, precision, and recall for the baseline, feature selection, and tuned models (baseline in blue, feature selection in orange, and tuned in green)}{figure.caption.7}{}}
\gdef \@abspage@last{6}
